{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# path to model code and weight\n",
    "path_pg_gan_code = './src/model/pggan'\n",
    "path_model = './asset_model/x-ray_integrated_20190218_network-snapshot-014000.pkl'\n",
    "sys.path.append(path_pg_gan_code)\n",
    "\n",
    "# path to model generated results\n",
    "path_gen_sample = './asset_results/pggan_x_ray_integrated_norm_sample_pkl/'\n",
    "path_fake_images = './data/x-ray_integrated_norm/'\n",
    "if not os.path.exists(path_gen_sample):\n",
    "    os.mkdir(path_gen_sample)\n",
    "if not os.path.exists(path_fake_images):\n",
    "    os.mkdir(path_fake_images)\n",
    "\n",
    "\"\"\" gen samples and save as pickle \"\"\"\n",
    "n_batch = 1000\n",
    "batch_size = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        with open(path_model, 'rb') as file:\n",
    "            G, D, Gs = pickle.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print('before running the code, download pre-trained model to project_root/asset_model/')\n",
    "        raise\n",
    "\n",
    "    # Generate latent vectors.\n",
    "    # latents = np.random.RandomState(1000).randn(1000, *Gs.input_shapes[0][1:]) # 1000 random latents\n",
    "    # latents = latents[[477, 56, 83, 887, 583, 391, 86, 340, 341, 415]] # hand-picked top-10\n",
    "    latents = np.random.RandomState(1000).randn(n_batch * batch_size, *Gs.input_shapes[0][1:])\n",
    "    \n",
    "    for i_batch in tqdm(range(n_batch)):\n",
    "        i_sample = i_batch * batch_size\n",
    "\n",
    "        p_latents = latents[i_batch:i_batch+batch_size]\n",
    "        labels = np.zeros([p_latents.shape[0]] + Gs.input_shapes[1][1:])\n",
    "\n",
    "        # Run the generator to produce a set of images.\n",
    "        images = Gs.run(p_latents, labels)\n",
    "        images = np.clip(np.rint((images + 1.0) / 2.0 * 255.0), 0.0, 255.0).astype(np.uint8)  # [-1,1] => [0,255]\n",
    "        images = images.transpose(0, 2, 3, 1)  # NCHW => NHWC\n",
    "        images = images.reshape(p_latents.shape[0],1024,1024)\n",
    "            \n",
    "            \n",
    "        # Save images as PNG.\n",
    "        for idx in range(images.shape[0]):\n",
    "            path = path_fake_images+'img%06d.png'%int(idx+i_batch)\n",
    "            if os.path.exists(path):\n",
    "                continue\n",
    "            PIL.Image.fromarray(images[idx], 'L').save(path)\n",
    "\n",
    "        path_pickle = os.path.join(path_gen_sample, 'pggan_x_ray_integrated_norm_{:0>6d}.pkl'.format(i_sample))\n",
    "        with open(path_pickle, 'wb') as f:\n",
    "            pickle.dump({'z': p_latents, 'x': images}, f)\n",
    "            \n",
    "        del p_latents, labels, images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
