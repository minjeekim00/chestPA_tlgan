{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "import src.tl_gan.get_normal_images as get_normal_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" start tf session and load GAN model \"\"\"\n",
    "\n",
    "# path to model code and weight\n",
    "path_pg_gan_code = './src/model/pggan'\n",
    "path_model = './asset_model/x-ray_integrated_20190218_network-snapshot-014000.pkl'\n",
    "sys.path.append(path_pg_gan_code)\n",
    "path_gan_explore = './asset_results/pggan_x_ray_integrated_norm_axis_explore/'\n",
    "\n",
    "\"\"\" get feature direction vector \"\"\"\n",
    "path_feature_direction = './asset_results/pg_gan_x_ray_integrated_norm_feature_direction_5/'\n",
    "pathfile_feature_direction = glob.glob(os.path.join(path_feature_direction, 'feature_direction_*.pkl'))[-1]\n",
    "\n",
    "with open(pathfile_feature_direction, 'rb') as f:\n",
    "    feature_direction_name = pickle.load(f)\n",
    "\n",
    "feature_direction = feature_direction_name['direction']\n",
    "feature_name = feature_direction_name['name']\n",
    "num_feature = feature_direction.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" play with the latent space \"\"\"\n",
    "sess = tf.InteractiveSession()\n",
    "with open(path_model, 'rb') as file:\n",
    "    G, D, Gs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step_sizes = [1, 0.25 ,0.25, 0.25] \n",
    "batch_size = 40\n",
    "\n",
    "#latents_n = get_normal_images.get_single_image()\n",
    "handpicked = [1987, 3774, 5332]\n",
    "latents_n = get_normal_images.get_all_images()[handpicked]# hand-picked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_latent, latent_n in enumerate(latents_n):\n",
    "    for i_feature in range(feature_direction.shape[1]):\n",
    "        latents = np.random.randn(batch_size, *Gs.input_shapes[0][1:])\n",
    "        for i, alpha in enumerate(range(batch_size)):\n",
    "            step_size = step_sizes[(i_feature)]\n",
    "            latents[i, :] = latent_n + (feature_direction[:, i_feature][None, :][0] * (step_size * alpha))\n",
    "\n",
    "        # Generate dummy labels (not used by the official networks).\n",
    "        labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
    "        # Run the generator to produce a set of images.\n",
    "        images = Gs.run(latents, labels)\n",
    "        images = np.clip(np.rint((images + 1.0) / 2.0 * 255.0), 0.0, 255.0).astype(np.uint8)  # [-1,1] => [0,255]\n",
    "        images = images.transpose(0, 2, 3, 1)  # NCHW => NHWC\n",
    "        images = images.reshape(latents.shape[0],1024,1024)\n",
    "\n",
    "        import datetime\n",
    "        time_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Save images as PNG.\n",
    "        for idx in range(images.shape[0]):\n",
    "            PIL.Image.fromarray(images[idx], 'L').save(os.path.join(path_gan_explore, 'img_{}_{}_{}.png'.format(handpicked[i_latent], i_feature, idx)))\n",
    "        #np.save(os.path.join(path_gan_explore, 'img_{}_{}.pkl'.format(time_str, i_feature)), labels)\n",
    "\n",
    "##\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate cam images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from src.model.chestPA_classifier.cam import plot_cam, classes\n",
    "\n",
    "n = batch_size * len(step_sizes)\n",
    "b = batch_size\n",
    "# hand-picked images\n",
    "total_images = [sorted(glob.glob(os.path.join(path_gan_explore, 'img_{}_*.png'.format(i))), key=os.path.getmtime) for i in handpicked]\n",
    "\n",
    "## generate CAM\n",
    "for case_idx, images in enumerate(total_images): # case별\n",
    "    for class_idx, images_per_class in enumerate([images[0:b], images[b:b*2], images[b*2:b*3], images[b*3:]]): # class별\n",
    "        #plot_cam(dataset_test=images_per_class, plot_fig=True, show_cam=True, save_fig=True, desired_dir=\"./results/{}\".format(handpicked[case_idx]))\n",
    "        cams_by_handpicked = sorted(glob.glob('./results/{}/img_{}_{}_*.png'.format(handpicked[case_idx], handpicked[case_idx], class_idx)), key=os.path.getmtime)\n",
    "        images = []\n",
    "        for filename in cams_by_handpicked:\n",
    "            images.append(imageio.imread(filename))\n",
    "        #imageio.mimsave('./results/{}/cam_{}.gif'.format(handpicked[case_idx], classes[class_idx+1]), images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
