{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" functions to regress y (labels) based on z (latent space) \"\"\"\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "import src.misc as misc\n",
    "import src.tl_gan.feature_axis as feature_axis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get y and z from pre-generated files \"\"\"\n",
    "path_gan_sample_img = './asset_results/pggan_x_ray_integrated_norm_sample_jpg/'\n",
    "#path_celeba_att = './data/raw/celebA_annotation/list_attr_celeba.txt'\n",
    "path_feature_direction = './asset_results/pg_gan_x_ray_integrated_norm_feature_direction_5/'\n",
    "\n",
    "filename_sample_y = 'sample_y.h5'\n",
    "filename_sample_z = 'sample_z.h5'\n",
    "\n",
    "pathfile_y = os.path.join(path_gan_sample_img, filename_sample_y)\n",
    "pathfile_z = os.path.join(path_gan_sample_img, filename_sample_z)\n",
    "\n",
    "with h5py.File(pathfile_y, 'r') as f:\n",
    "    y = f['y'][:]\n",
    "with h5py.File(pathfile_z, 'r') as f:\n",
    "    z = f['z'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for normal images\n",
    "filename_normal_z = 'normal_z.h5'\n",
    "pathfile_normal_z = os.path.join(path_gan_sample_img, filename_normal_z)\n",
    "with h5py.File(pathfile_normal_z, 'r') as f:\n",
    "    z_normal = f['z'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
    "#y_onehot = np.eye(len(y), 5, dtype=np.int8)[y.reshape(-1)]\n",
    "#y_name = ['00Normal', '01Nodule', '03Consolidation', '04InterstitialOpacity','10PleuralEffusion']\n",
    "y_onehot = np.eye(len(y), 4, dtype=np.int8)[(y - 1).reshape(-1)]\n",
    "y_name = ['01Nodule', '03Consolidation', '04InterstitialOpacity','10PleuralEffusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression: latent space z to predict features y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "\"\"\" regression: use latent space z to predict features y \"\"\"\n",
    "method ='linear'\n",
    "feature_slope = feature_axis.find_feature_axis(z, y_onehot, method=method)\n",
    "\n",
    "\"\"\" normalize the feature vectors \"\"\"\n",
    "yn_normalize_feature_direction = True\n",
    "if yn_normalize_feature_direction:\n",
    "    feature_direction = feature_axis.normalize_feature_axis(feature_slope)\n",
    "else:\n",
    "    feature_direction = feature_slope\n",
    "    \n",
    "\"\"\" save_regression result to hard disk \"\"\"\n",
    "if not os.path.exists(path_feature_direction):\n",
    "    os.mkdir(path_feature_direction)\n",
    "    \n",
    "pathfile_feature_direction = os.path.join(path_feature_direction, 'feature_direction_{}_{}.pkl'.format(method, misc.gen_time_str()))\n",
    "dict_to_save = {'direction': feature_direction, 'name': y_name}\n",
    "with open(pathfile_feature_direction, 'wb') as f:\n",
    "    pickle.dump(dict_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" disentangle correlated feature axis \"\"\"\n",
    "pathfile_feature_direction = glob.glob(os.path.join(path_feature_direction, 'feature_direction_*.pkl'))[-1]\n",
    "\n",
    "with open(pathfile_feature_direction, 'rb') as f:\n",
    "    feature_direction_name = pickle.load(f)\n",
    "\n",
    "feature_direction = feature_direction_name['direction']\n",
    "feature_name = np.array(feature_direction_name['name'])\n",
    "\n",
    "len_z, len_y = feature_direction.shape\n",
    "\n",
    "feature_direction_disentangled = feature_axis.disentangle_feature_axis_by_idx(\n",
    "    feature_direction, idx_base=range(len_y), idx_target=None)\n",
    "\n",
    "feature_axis.plot_feature_cos_sim(feature_direction_disentangled, feature_name=feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction & plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "X = z\n",
    "Y = y-1\n",
    "target_names = y_name\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_r2 = lda.fit(X, Y).transform(X)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_r3 = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise', 'darkorange', 'pink']\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1, 2, 3], target_names):\n",
    "    plt.scatter(X_r[Y == i, 0], X_r[Y == i, 1], color=color, alpha=.8, lw=lw,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA')\n",
    "\n",
    "plt.figure()\n",
    "for color, i, target_name in zip(colors, [0, 1, 2, 3], target_names):\n",
    "    plt.scatter(X_r2[Y == i, 0], X_r2[Y == i, 1], alpha=.5, color=color,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA')\n",
    "\n",
    "plt.figure()\n",
    "for color, i, target_name in zip(colors, [0, 1, 2, 3], target_names):\n",
    "    plt.scatter(X_r3[Y == i, 0], X_r3[Y == i, 1], alpha=.5, color=color,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('T-SNE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "n_sne = z.shape[0]\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(df.loc[:,feat_cols].values)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "df_tsne = df.loc[:,:].copy()\n",
    "df_tsne['x-tsne'] = tsne_results[:,0]\n",
    "df_tsne['y-tsne'] = tsne_results[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = ggplot( df_tsne, aes(x='x-tsne', y='y-tsne', color='class') ) \\\n",
    "        + geom_point(size=70,alpha=0.5) \\\n",
    "        + ggtitle(\"tSNE dimensions colored by class\") \\\n",
    "        + xlim(-15, 15) \\\n",
    "        + ylim(-15, 15)\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test discovered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test_discovered features \"\"\"\n",
    "# path to model code and weight\n",
    "path_pg_gan_code = './src/model/pggan/'\n",
    "path_model = './asset_model/x-ray_integrated_20190218_network-snapshot-014000.pkl'\n",
    "sys.path.append(path_pg_gan_code)\n",
    "\n",
    "path_gan_explore = './asset_results/pggan_x_ray_integrated_norm_axis_explore/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" play with the latent space \"\"\"\n",
    "sess = tf.InteractiveSession()\n",
    "with open(path_model, 'rb') as file:\n",
    "    G, D, Gs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "latents_c = z_normal[0]\n",
    "for i_feature in range(1, feature_direction.shape[1]):\n",
    "    #latents_0 = latents_c - feature_direction[:, i_feature][None, :]*2\n",
    "    latents_0 = latents_c\n",
    "    latents_1 = latents_c + feature_direction[:, i_feature][None, :]*2\n",
    "    \n",
    "    latents = np.random.randn(batch_size, *Gs.input_shapes[0][1:])\n",
    "    for i_alpha, alpha in enumerate(np.linspace(0, 1, batch_size)):\n",
    "        latents[i_alpha, :] = latents_0[0]*(1-alpha) + latents_1[0]*alpha\n",
    "        print((latents_0[0]*(1-alpha)).shape, (latents_1[0]*alpha).shape)\n",
    "    # Generate dummy labels (not used by the official networks).\n",
    "    labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
    "    # Run the generator to produce a set of images.\n",
    "    images = Gs.run(latents, labels)\n",
    "    images = np.clip(np.rint((images + 1.0) / 2.0 * 255.0), 0.0, 255.0).astype(np.uint8)  # [-1,1] => [0,255]\n",
    "    images = images.transpose(0, 2, 3, 1)  # NCHW => NHWC\n",
    "    images = images.reshape(latents.shape[0],1024,1024)\n",
    "    \n",
    "    time_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Save images as PNG.\n",
    "    #for idx in range(images.shape[0]):\n",
    "    #    PIL.Image.fromarray(images[idx], 'L').save(os.path.join(path_gan_explore,\n",
    "                                                                  'img_{}_{}_{}.png'.format(time_str, i_feature, idx)))\n",
    "    #np.save(os.path.join(path_gan_explore, 'img_{}_{}.pkl'.format(time_str, i_feature)), labels)\n",
    "\n",
    "##\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
